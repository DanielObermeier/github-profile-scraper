{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper - Github Repo - check whether users work at repo company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script queries startpage to check whether a github user works at the repo's company. \n",
    "To do so, it proceeds in three steps:\n",
    "\n",
    "1. It initiates a webdriver (headless or normal) \n",
    "2. It defines a function, that takes the real user names and company name as an argument and returns startpage search results\n",
    "3. It takes a json file and queries users and appends this json with search results \n",
    "\n",
    "This script requires a json file containing real user names and company names. To get this file, use \"Scraping Github Profiles - Get real names.ipynb.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initiate Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function uses selenium and chromedriver to search startpage for name, company, and \"linkedin\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Init webdriver - webdriver is initiated outside of the function to increase speed\n",
    "\"\"\"\n",
    "    # Init webdriver headless to increase performance\n",
    "# get path of webdriver\n",
    "chrome_driver = webdriver.Chrome(\"D:/Drive/01_Promotion/31_Code/01_Python/GitHub Readme/chromedriver.exe\")\n",
    "    # set options of webdriver to headless\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "    # set screensize to 1920x1080\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\"\"\"\n",
    "\n",
    "#driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=chrome_driver)\n",
    "\n",
    "    # Init webdriver normally to see mistakes\n",
    "driver = webdriver.Chrome(\"D:/Drive/01_Promotion/31_Code/01_Python/GitHub Readme/chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# navigate webdriver\n",
    "try:\n",
    "    driver.get(\"https://www.startpage.com/\")\n",
    "except:\n",
    "    print(\"webdriver failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define function that queries startparge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startpage\n",
    "# this function takes the real user name and company name as arguments, inserts it in a duckduckgo query and checks whether name and company appear in the same text snippet of a search result. Snippet and Boolean are returned as dictionary. \n",
    "\n",
    "\n",
    "def working_in_company(real_user_name, company_name):\n",
    "\n",
    "    working_in = dict()\n",
    "\n",
    "    import time\n",
    "    from random import randrange, uniform\n",
    "    \n",
    "    \n",
    "    search = driver.find_element_by_name('query')\n",
    "    search.send_keys(Keys.CONTROL, 'a')\n",
    "    search.send_keys(Keys.BACKSPACE)\n",
    "    time.sleep(uniform(0.5,0.7))\n",
    "    search.send_keys(real_user_name+\",\"+company_name+\",\"+\"linkedin\") #enter search terms here\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(uniform(1.2, 1.9))\n",
    "\n",
    "    ######\n",
    "    # add try except loop to solve section shift because of add\n",
    "    ######\n",
    "    try:\n",
    "        startpage_snip_1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[1]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[1]/p').text \n",
    "        LinkedIn_link_1 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[1]/a\").get_attribute('href')\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            startpage_snip_1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[1]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[1]/p').text  \n",
    "            LinkedIn_link_1 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[1]/a\").get_attribute('href') \n",
    "        except:\n",
    "            try: \n",
    "                startpage_snip_1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[1]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[1]/p').text  \n",
    "                LinkedIn_link_1 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[1]/a\").get_attribute('href') \n",
    "            except:\n",
    "                try:\n",
    "                    startpage_snip_1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[1]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[1]/p').text  \n",
    "                    LinkedIn_link_1 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[1]/a\").get_attribute('href') \n",
    "                except:\n",
    "                    try:\n",
    "                        startpage_snip_1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[1]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[1]/p').text  \n",
    "                        LinkedIn_link_1 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[1]/a\").get_attribute('href') \n",
    "                    except:\n",
    "                        startpage_snip_1 = \"\"\n",
    "                        LinkedIn_link_1 = \"\"\n",
    "\n",
    "    try:\n",
    "        startpage_snip_2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[2]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[2]/p').text \n",
    "        LinkedIn_link_2 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[2]/a\").get_attribute('href')\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            startpage_snip_2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[2]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[2]/p').text\n",
    "            LinkedIn_link_2 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[2]/a\").get_attribute('href')   \n",
    "        except:\n",
    "            try: \n",
    "                startpage_snip_2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[2]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[2]/p').text  \n",
    "                LinkedIn_link_2 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[2]/a\").get_attribute('href') \n",
    "            except:\n",
    "                startpage_snip_2 = \"\"\n",
    "                LinkedIn_link_2 = \"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        startpage_snip_3 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[3]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[3]/p').text \n",
    "        LinkedIn_link_3 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[3]/a\").get_attribute('href')\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            startpage_snip_3 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[3]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[3]/p').text   \n",
    "            LinkedIn_link_3 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[3]/a\").get_attribute('href')\n",
    "        except:\n",
    "            try: \n",
    "                startpage_snip_3 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[3]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[3]/p').text  \n",
    "                LinkedIn_link_3 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[3]/a\").get_attribute('href') \n",
    "            except:\n",
    "                try:\n",
    "                    startpage_snip_3 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[3]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[3]/p').text  \n",
    "                    LinkedIn_link_3 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[3]/a\").get_attribute('href') \n",
    "                \n",
    "                except:\n",
    "                    try:\n",
    "                        startpage_snip_3 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[3]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[3]/p').text  \n",
    "                        LinkedIn_link_3 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[3]/a\").get_attribute('href') \n",
    "                    except:\n",
    "                        startpage_snip_3 = \"\"\n",
    "                        LinkedIn_link_3 = \"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        startpage_snip_4 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[4]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[4]/p').text \n",
    "        LinkedIn_link_4 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[5]/div[4]/a\").get_attribute('href')\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            startpage_snip_4 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[4]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[4]/p').text   \n",
    "            LinkedIn_link_4 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[6]/div[4]/a\").get_attribute('href')\n",
    "        except:\n",
    "            try: \n",
    "                startpage_snip_4 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[4]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[4]/p').text  \n",
    "                LinkedIn_link_4 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[4]/div[4]/a\").get_attribute('href') \n",
    "            except:\n",
    "                try:\n",
    "                    startpage_snip_4 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[4]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[4]/p').text  \n",
    "                    LinkedIn_link_4 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[3]/div[4]/a\").get_attribute('href') \n",
    "                except:\n",
    "                    try:\n",
    "                        startpage_snip_4 = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[4]/a/h3').text +\" || \" +driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[4]/p').text  \n",
    "                        LinkedIn_link_4 =  driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[1]/div[2]/div[1]/div/section[2]/div[4]/a\").get_attribute('href') \n",
    "                    except:\n",
    "                        startpage_snip_4 = \"\"\n",
    "                        LinkedIn_link_4 = \"\"\n",
    "\n",
    "\n",
    "    if \"linkedin\" in LinkedIn_link_1.lower():\n",
    "        working_in[\"LinkedIn Link_1\"] = LinkedIn_link_1\n",
    "    else: \n",
    "        working_in[\"LinkedIn Link_1\"] = \"no profile found\"\n",
    "\n",
    "    if \"linkedin\" in LinkedIn_link_2.lower():\n",
    "        working_in[\"LinkedIn Link_2\"] = LinkedIn_link_2\n",
    "    else: \n",
    "        working_in[\"LinkedIn Link_2\"] = \"no profile found\"\n",
    "\n",
    "    if \"linkedin\" in LinkedIn_link_3.lower():\n",
    "        working_in[\"LinkedIn Link_3\"] = LinkedIn_link_3\n",
    "    else: \n",
    "        working_in[\"LinkedIn Link_3\"] = \"no profile found\"    \n",
    "\n",
    "    if \"linkedin\" in LinkedIn_link_4.lower():\n",
    "        working_in[\"LinkedIn Link_4\"] = LinkedIn_link_4\n",
    "    else: \n",
    "        working_in[\"LinkedIn Link_4\"] = \"no profile found\"    \n",
    "\n",
    "\n",
    "    working_in[\"snippet_1\"] = startpage_snip_1\n",
    "    working_in[\"snippet_2\"] = startpage_snip_2\n",
    "    working_in[\"snippet_3\"] = startpage_snip_3\n",
    "    working_in[\"snippet_4\"] = startpage_snip_4\n",
    "\n",
    "\n",
    "    working_in[\"works in company_1\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_1.lower().replace(\" \",\"\") and real_user_name.lower().replace(\" \",\"\") in startpage_snip_1.lower().replace(\" \",\"\")\n",
    "    working_in[\"works in company_2\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_2.lower().replace(\" \",\"\") and real_user_name.lower().replace(\" \",\"\") in startpage_snip_2.lower().replace(\" \",\"\")\n",
    "    working_in[\"works in company_3\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_3.lower().replace(\" \",\"\") and real_user_name.lower().replace(\" \",\"\") in startpage_snip_3.lower().replace(\" \",\"\")\n",
    "    working_in[\"works in company_4\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_4.lower().replace(\" \",\"\") and real_user_name.lower().replace(\" \",\"\") in startpage_snip_4.lower().replace(\" \",\"\")\n",
    "\n",
    "    working_in[\"company found_1\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_1.lower().replace(\" \",\"\")\n",
    "    working_in[\"company found_2\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_2.lower().replace(\" \",\"\")\n",
    "    working_in[\"company found_3\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_3.lower().replace(\" \",\"\")\n",
    "    working_in[\"company found_4\"] = company_name.lower().replace(\" \",\"\") in startpage_snip_4.lower().replace(\" \",\"\")\n",
    "\n",
    "   \n",
    "\n",
    "    return working_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test errors\n",
    "\n",
    "# print(working_in_company(\"Vamshi Surabhi\",\"Hasura\"))\n",
    "# print(working_in_company(\"0xAX\",\"Travelping GmbH\"))\n",
    "# print(working_in_company(\"Florian Rival\",\"Theodo\")) # previously not found\n",
    "\n",
    "#result = working_in_company(\"OlivierDehaene\",\"Manzalab\")\n",
    "#print(result[\"works in company_1\"],result[\"works in company_2\"],result[\"works in company_3\"],result[\"works in company_4\"])\n",
    "#print(result[\"snippet_1\"])\n",
    "#print(result[\"snippet_2\"])\n",
    "#print(result[\"snippet_3\"])\n",
    "#print(result[\"snippet_4\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fr.linkedin.com/in/benfradet\n",
      "Ben Fradet - Senior Software Engineer - 47 Degrees | LinkedIn || Découvrez le profil de Ben Fradet sur LinkedIn, la plus grande communauté professionnelle au monde. Ben indique 5 postes sur son profil. Consultez le profil ...\n"
     ]
    }
   ],
   "source": [
    "result = working_in_company(\"Ben Fradet\", \"47 Degrees\")\n",
    "print(result[\"LinkedIn Link_1\"])\n",
    "print(result[\"snippet_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loop through users, calls function to query startpage, and store results in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users have already been queried\n",
      "queried 1 users\n",
      "queried 10493 users\n",
      "queried 10494 users\n",
      "all user/company combinations have been queried\n"
     ]
    }
   ],
   "source": [
    "# open json file which stores all real user names and company names \n",
    "import json\n",
    "import ast\n",
    "\n",
    "result_list = []\n",
    "already_queried_list = []\n",
    "queried_counter = 0\n",
    "counter = 0\n",
    "autosave = 0\n",
    "\n",
    "# path to json containing user and company names \n",
    "\n",
    "path_to_json_import = r\"D:\\Drive\\01_Promotion\\31_Code\\01_Python\\Obermeier Starpage scraper\\user_names_queried_Target.json\"\n",
    "\n",
    "path_to_json_result = r\"D:\\Drive\\01_Promotion\\31_Code\\01_Python\\Obermeier Starpage scraper\\user_working_at_company_queried_Target.json\"\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(path_to_json_result,\"r\") as json_file:\n",
    "        queried_data = json.load(json_file)\n",
    "        for user in queried_data:\n",
    "            del queried_data[22592:]\n",
    "            already_queried_key = user[\"login\"]+user[\"company\"]\n",
    "            already_queried_list.append(already_queried_key)\n",
    "            result_list.append(user)\n",
    "            queried_counter += 1\n",
    "except:\n",
    "    already_queried_list = []\n",
    "print(queried_counter, \"users have already been queried\")\n",
    "with open(path_to_json_import,\"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for user in data:\n",
    "        check_already_queried_key = user[\"login\"]+user[\"company\"]\n",
    "        # only query users which have not been queried before\n",
    "        if check_already_queried_key not in already_queried_list:\n",
    "            \n",
    "            # if no user name is indicated, use login to query user\n",
    "            if user[\"real_user_name\"] == \"noname\" or user[\"real_user_name\"] == None:\n",
    "                try: \n",
    "                    result_dict = working_in_company(user[\"login\"], user[\"company\"])\n",
    "                except:\n",
    "                    print(\"could not query login;\", user[\"login\"],\"at company:\", user[\"company\"])\n",
    "                    # if user could not be queried add empty cells\n",
    "                    result_dict[\"snippet_1\"] = \"\"\n",
    "                    result_dict[\"snippet_2\"] = \"\"\n",
    "                    result_dict[\"snippet_3\"] = \"\"\n",
    "                    result_dict[\"snippet_4\"] = \"\"\n",
    "                    result_dict[\"works in company_1\"] = \"\"\n",
    "                    result_dict[\"works in company_2\"] = \"\"\n",
    "                    result_dict[\"works in company_3\"] = \"\"\n",
    "                    result_dict[\"works in company_4\"] = \"\"\n",
    "                    result_dict[\"LinkedIn link_1\"] = \"\"\n",
    "                    result_dict[\"LinkedIn link_2\"] = \"\"\n",
    "                    result_dict[\"LinkedIn link_3\"] = \"\"\n",
    "                    result_dict[\"LinkedIn link_4\"] = \"\"\n",
    "                    result_dict[\"company found_1\"] = \"\"\n",
    "                    result_dict[\"company found_2\"] = \"\"\n",
    "                    result_dict[\"company found_3\"] = \"\"\n",
    "                    result_dict[\"company found_4\"] = \"\"\n",
    "                    print(\"stopped early - after:\", counter)\n",
    "                    #break\n",
    "            else:\n",
    "                try: \n",
    "                    result_dict = working_in_company(user[\"real_user_name\"], user[\"company\"])\n",
    "                except:\n",
    "                    print(\"could not query user;\", user[\"real_user_name\"],\"at company:\", user[\"company\"])\n",
    "                    # if user could not be queried add empty cells\n",
    "                    result_dict[\"snippet_1\"] = \"\"\n",
    "                    result_dict[\"snippet_2\"] = \"\"\n",
    "                    result_dict[\"snippet_3\"] = \"\"\n",
    "                    result_dict[\"snippet_4\"] = \"\"\n",
    "                    result_dict[\"works in company_1\"] = \"\"\n",
    "                    result_dict[\"works in company_2\"] = \"\"\n",
    "                    result_dict[\"works in company_3\"] = \"\"\n",
    "                    result_dict[\"works in company_4\"] = \"\"\n",
    "                    result_dict[\"LinkedIn Link_1\"] = \"\"\n",
    "                    result_dict[\"LinkedIn Link_2\"] = \"\"\n",
    "                    result_dict[\"LinkedIn Link_3\"] = \"\"\n",
    "                    result_dict[\"LinkedIn Link_4\"] = \"\"\n",
    "                    result_dict[\"company found_1\"] = \"\"\n",
    "                    result_dict[\"company found_2\"] = \"\"\n",
    "                    result_dict[\"company found_3\"] = \"\"\n",
    "                    result_dict[\"company found_4\"] = \"\"\n",
    "                    print(\"stopped early - after:\", counter)\n",
    "                    #break\n",
    "            # store results in user dict \n",
    "            user[\"snippet_1\"] = result_dict[\"snippet_1\"]\n",
    "            user[\"snippet_2\"] = result_dict[\"snippet_2\"]\n",
    "            user[\"snippet_3\"] = result_dict[\"snippet_3\"]\n",
    "            user[\"snippet_4\"] = result_dict[\"snippet_4\"]\n",
    "            user[\"works in company_1\"] = result_dict[\"works in company_1\"]\n",
    "            user[\"works in company_2\"] = result_dict[\"works in company_2\"]\n",
    "            user[\"works in company_3\"] = result_dict[\"works in company_3\"]\n",
    "            user[\"works in company_4\"] = result_dict[\"works in company_4\"]\n",
    "            user[\"company found_1\"] = result_dict[\"company found_1\"]\n",
    "            user[\"company found_2\"] = result_dict[\"company found_2\"]\n",
    "            user[\"company found_3\"] = result_dict[\"company found_3\"]\n",
    "            user[\"company found_4\"] = result_dict[\"company found_4\"]\n",
    "            user[\"LinkedIn Link_1\"] = result_dict[\"LinkedIn Link_1\"]\n",
    "            user[\"LinkedIn Link_2\"] = result_dict[\"LinkedIn Link_2\"]\n",
    "            user[\"LinkedIn Link_3\"] = result_dict[\"LinkedIn Link_3\"]\n",
    "            user[\"LinkedIn Link_4\"] = result_dict[\"LinkedIn Link_4\"]\n",
    "            \n",
    "            # add user dict to result list\n",
    "            result_list.append(user)\n",
    "            autosave += 1\n",
    "            counter +=1 \n",
    "            print(\"queried\", counter, \"users\")\n",
    "            # print(user[\"works in company_1\"],user[\"works in company_2\"], user[\"works in company_3\"])\n",
    "        # autosave after 1000 queries \n",
    "        if autosave == 250:\n",
    "            autosave = 0 # reset autosave counter\n",
    "            with open(path_to_json_result, \"w\") as json_file:\n",
    "                json.dump(result_list, json_file)\n",
    "            print(\"autosave completed\")\n",
    "# save results to already queried dataset\n",
    "with open(path_to_json_result, \"w\") as json_file:\n",
    "    json.dump(result_list, json_file)\n",
    "print(\"all user/company combinations have been queried\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Query problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Query problems:\n",
    "\n",
    "1. Error: Snippets but no match - [Real user Name] and [Login] are no real names -> cannot find real user name in snippet: \n",
    "\n",
    "    e.g. (\"0xAX\",\"Travelping GmbH\")\n",
    "\n",
    "1a. Error: Snippets but no match - [Real user Name] and [Company] are correct -> linkedin hit does not show comapny as user has too many current jobs: \n",
    "\n",
    "    e.g. (\"Jason Spradlin\",\"The Nerdery\") -  google finds user at Company\n",
    "\n",
    "2. Error: Snippets but no match - [Users] where false linkedin profile (i.e. differnet person with same name, poi not within 3 top hits) are found cannot be checked: \n",
    "\n",
    "    e.g. (\"Eli Dai\",\"Learning Equality\")\n",
    "\n",
    "3. Error: No snippet found - Has real user name but with special characters -> no search engine hit \n",
    "    \n",
    "    e.g. (\"Filip DolnÃ­k\",\"Brightify\") or (\"Kevin Gaudet\", \"IRCAD Institut de Recherche contre les Cancers de lâ€šÃ„Ã´Appareil Digestif\")\n",
    "\n",
    "\n",
    "\n",
    "1100 not working at company (if snippet)\n",
    "311 no snippet\n",
    "\n",
    "\n",
    "no snippet but has real user name -> sollte geklärt sein oder gibt es noch mehr sections?\n",
    "\n",
    "no snippet because  has no real user name\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert json result file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're done! Lean back feel good an relax...\n"
     ]
    }
   ],
   "source": [
    "# convert result json to csv\n",
    "import pandas as pd\n",
    "\n",
    "# which result json do you want to convert to csv?\n",
    "path_to_result_json = r'D:\\Drive\\01_Promotion\\31_Code\\01_Python\\Obermeier Starpage scraper\\user_working_at_company_queried_v9.json'\n",
    "\n",
    "# where do you want to store the final csv file?\n",
    "path_to_result_csv =r'D:\\Drive\\01_Promotion\\31_Code\\01_Python\\Obermeier Starpage scraper\\user_working_at_company_queried_v9.csv'\n",
    "\n",
    "df = pd.read_json (path_to_result_json)\n",
    "df.to_csv (path_to_result_csv, index = None, header =True)\n",
    "\n",
    "print(\"You're done! Lean back feel good an relax...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}